{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGrowth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hnswlib\n",
    "from numpy import linalg as LA\n",
    "\n",
    "def cosine_sim(x,y):\n",
    "    return np.dot(x,y)/LA.norm(x)/LA.norm(y)\n",
    "\n",
    "class DataPair:\n",
    "    def __init__(self, Image_path, Text, I_feature, T_feature):\n",
    "        self.Image_path=Image_path\n",
    "        self.Text=Text\n",
    "        self.I_feature=I_feature\n",
    "        self.T_feature=T_feature\n",
    "        self.index = None\n",
    "\n",
    "    def I_sim(self, point):\n",
    "        return cosine_sim(self.I_feature, point.I_feature)\n",
    "\n",
    "    def I_distance(self, points):\n",
    "        if type(points).__name__=='DataPair':\n",
    "            return 1.-cosine_sim(self.I_feature, points.I_feature)\n",
    "        elif type(points) is list:\n",
    "            return np.array([1.-cosine_sim(self.I_feature, p.I_feature) for p in points])\n",
    "        else:\n",
    "            raise TypeError(\"data should be list or DataPair!\")\n",
    "\n",
    "    def T_distance(self, points):\n",
    "        if type(points).__name__=='DataPair':\n",
    "            return 1.-cosine_sim(self.T_feature,points.T_feature)\n",
    "        elif type(points) is list:\n",
    "            return np.array([1.-cosine_sim(self.T_feature, p.T_feature) for p in points])\n",
    "        else:\n",
    "            raise TypeError(\"data should be list or DataPair!\")\n",
    "\n",
    "\n",
    "class InfoGrowth:\n",
    "    # New incoming data should have comparable cleaness as bootstraping set.\n",
    "    # Current version handle million scale on single machine; \n",
    "    # For larger scale, consider using hyperplane (vector space separation) \n",
    "    # to further distribute samples across machines;\n",
    "    # and the HNSW can be further modified or replaced for better concurrency.\n",
    "\n",
    "    def __init__(self, initial_points=None, n=3000000, keep_seed=False, submodular_k=4):\n",
    "        self.clusters = None\n",
    "        self.target_n = n\n",
    "        self.current_n = 0\n",
    "        self.keep_seed = keep_seed\n",
    "        self.dim = 256\n",
    "        self.submodular_k = submodular_k\n",
    "\n",
    "        if initial_points: \n",
    "            self.data = initial_points.copy()\n",
    "            self.current_n = len(initial_points)\n",
    "            if keep_seed:\n",
    "                self.seeded_num = len(initial_points)\n",
    "            self.dim = len(initial_points[0].I_feature)\n",
    "        else:\n",
    "            self.data = []\n",
    "        self.submodular_gain = [(1,1)]*len(self.data)\n",
    "\n",
    "        # initialize HNSW index\n",
    "        self.I_knn_graph = hnswlib.Index(space='cosine', dim=self.dim)\n",
    "        self.I_knn_graph.init_index(max_elements=n, ef_construction=100, M=48, allow_replace_deleted = False)\n",
    "        self.T_knn_graph = hnswlib.Index(space='cosine', dim=self.dim)\n",
    "        self.T_knn_graph.init_index(max_elements=n, ef_construction=100, M=48, allow_replace_deleted = False)\n",
    "        self.precluster(initial_points)\n",
    "\n",
    "        self.I_knn_graph.set_ef(32)\n",
    "        self.T_knn_graph.set_ef(32)\n",
    "        self.min_align = 0.4\n",
    "\n",
    "\n",
    "    def precluster(self, initial_points):\n",
    "    # Starting from some initial points (the cleaner the better) to do online selection\n",
    "        if initial_points is None or initial_points==[]: return\n",
    "        for idx,data in enumerate(self.data):\n",
    "            data.index = idx\n",
    "\n",
    "        for idx,data in enumerate(self.data):\n",
    "            self.submodular_gain[idx] = self.submodular_func(data, True)\n",
    "            self.I_knn_graph.add_items(data.I_feature, idx)\n",
    "            self.T_knn_graph.add_items(data.T_feature, idx)\n",
    "            \n",
    "\n",
    "    def submodular_func(self, data, skip_one=False):\n",
    "        if self.I_knn_graph.get_current_count()==0:\n",
    "            return (1.,1.)\n",
    "        k = min(self.I_knn_graph.get_current_count(), self.submodular_k)\n",
    "        \n",
    "        I_near_labels, I_near_distances = self.k_nearest_neighbour_I(data, k)\n",
    "        T_near_labels, T_near_distances = self.k_nearest_neighbour_T(data, k)\n",
    "        return (np.mean(I_near_distances),np.mean(T_near_distances))\n",
    "\n",
    "    def align_score(self,data):\n",
    "        if type(data).__name__=='DataPair':\n",
    "            return cosine_sim(data.I_feature,data.T_feature)\n",
    "        elif type(data) is list:\n",
    "            return [self.align_score(x) for x in data]\n",
    "        else:\n",
    "            raise TypeError(\"data should be list or DataPair!\")\n",
    "\n",
    "    def k_nearest_neighbour_I(self, data, k):\n",
    "        I_near_labels, I_near_distances = self.I_knn_graph.knn_query(data.I_feature, k)\n",
    "        return I_near_labels, I_near_distances\n",
    "\n",
    "    def k_nearest_neighbour_T(self,data, k):\n",
    "        T_near_labels, T_near_distances = self.T_knn_graph.knn_query(data.T_feature, k)\n",
    "        return T_near_labels, T_near_distances\n",
    "\n",
    "    def I_to_T_k_nearest(self, data, k):\n",
    "        T_near_labels, T_near_distances = self.T_knn_graph.knn_query(data.I_feature, k)\n",
    "        return T_near_labels, T_near_distances\n",
    "\n",
    "    def T_to_I_k_nearest(self, data, k):\n",
    "        I_near_labels, I_near_distances = self.I_knn_graph.knn_query(data.T_feature, k)\n",
    "        return I_near_labels, I_near_distances\n",
    "\n",
    "    def add_item(self, data):\n",
    "        data.index = self.current_n\n",
    "        self.data.append(data)\n",
    "        self.I_knn_graph.add_items(data.I_feature, self.current_n)\n",
    "        self.T_knn_graph.add_items(data.T_feature, self.current_n)\n",
    "        self.current_n+=1\n",
    "\n",
    "    def replace_item(self, data, index):\n",
    "        # Not used in current work but provide for future extension on replacing samples\n",
    "        data_to_rep = self.data[index]\n",
    "        n_index = data_to_rep.index\n",
    "        data.index = self.current_n\n",
    "        self.I_knn_graph.mark_deleted(n_index)\n",
    "        self.T_knn_graph.mark_deleted(n_index)\n",
    "        self.I_knn_graph.add_items(data.I_feature, self.current_n, replace_deleted = True)\n",
    "        self.T_knn_graph.add_items(data.T_feature, self.current_n, replace_deleted = True)\n",
    "        self.data[index] = data\n",
    "        self.current_n+=1\n",
    "\n",
    "    def process_item(self, data: DataPair, recaptioner = None):\n",
    "        # find near clusters\n",
    "        # go into nearest clusters to search near neighbour\n",
    "        # calculate corresponding threshold to decide if try to add or not\n",
    "        align_score = self.align_score(data)\n",
    "        if recaptioner and data.Image_path in recaptioner:\n",
    "            text = recaptioner[data.Image_path]['caption']\n",
    "            recap_T_feature = recaptioner[data.Image_path]['text_feature']\n",
    "            recap_align_score = cosine_sim(data.I_feature,recap_T_feature)\n",
    "            if align_score<0.4 and recap_align_score>=0.4:\n",
    "                align_score = recap_align_score\n",
    "                data.Text = text\n",
    "                data.T_feature = recap_T_feature\n",
    "\n",
    "        if align_score<self.min_align:\n",
    "            return\n",
    "\n",
    "        gain = self.submodular_func(data)\n",
    "\n",
    "        self.add_item(data)\n",
    "        self.submodular_gain.append(gain)\n",
    "\n",
    "    def final_gains(self):\n",
    "        return self.submodular_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_to_DataPairs(d):\n",
    "    res = []\n",
    "    covered_index = set()\n",
    "    for idx in range(len(d['image_path'])):\n",
    "        if d['image_path'][idx]['image_path']in covered_index:\n",
    "            continue\n",
    "        else:\n",
    "            covered_index.add(d['image_path'][idx]['image_path'])\n",
    "            res.append(DataPair(d['image_path'][idx]['image_path'],\n",
    "                                                d['image_path'][idx]['text'],\n",
    "                                                d['image_feature_array'][idx],\n",
    "                                                d['text_feature_array'][idx]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To extract the blip features, run ```python3 process_features.py``` with setting corresponding file path in configs/feature_processing.yaml. You can also define your own implementation on other data structure and backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cc3m_dict = torch.load('/data/common/cc3m/blip_features/cc3m_raw_features.pth')\n",
    "cc3m_datapairs = dic_to_DataPairs(cc3m_dict)\n",
    "cc3m_lookup = {}\n",
    "for i,data in enumerate(cc3m_datapairs):\n",
    "    cc3m_lookup[data.Image_path]=i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize with a clean subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "clean_5 = json.load(open('top_5_percent_clean_captions.json'))\n",
    "clean_5_datapairs = [cc3m_datapairs[cc3m_lookup[d['image']]] for d in clean_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data to grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_10 = json.load(open('random_10_percent.json'))\n",
    "random_10_datapairs = [cc3m_datapairs[cc3m_lookup[d['image']]] for d in random_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a full recaption from MiniGPT-4. You can substitute it with other cleaner module. Will provide a 40k one later. For real-time online cleaning that takes longer inference time, consider using batched inputs and clean those filtered samples asynchrously during adding other samples, and add cleaned samples back to queue later when relabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recaptioner = torch.load('mini_text_feature_all.pth')\n",
    "recaptioner = {recaptioner['images'][i]:{'text_feature':recaptioner['text_feature_array'][i]} for i in range(len(recaptioner['images']))}\n",
    "mini_captions = json.load(open('cc3m_minigpt4.json'))\n",
    "for d in mini_captions:\n",
    "    if d['image'] in recaptioner:\n",
    "        recaptioner[d['image']]['caption'] = d['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy\n",
    "gd = InfoGrowth(clean_5_datapairs,submodular_k=4)\n",
    "for data in tqdm(random_10_datapairs):\n",
    "    gd.process_item(data,recaptioner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [{'image':data.Image_path, 'caption':data.Text} for data in gd.data]\n",
    "weights = gd.submodular_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dynamic two phase training, save the cleaned samples with gains for dataset loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [(str(x[0]),str(x[1])) for x in weights]\n",
    "for i in range(len(filelist)):\n",
    "    filelist[i]['gains'] = w[i]\n",
    "json.dump(filelist,open('40k_samples_k4.json','w+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For static selection, run the following instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gains = np.array([(float(x[0])+float(x[1]))/2. for x in weights])\n",
    "thr = np.quantile(gains,0.99)\n",
    "gains=gains/thr\n",
    "gains[gains>1]=1.\n",
    "gains[gains<0]=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
